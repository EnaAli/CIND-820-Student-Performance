---
title: "Student Performance prediction-Multiple Linear Regression- Portuguese Dataset"
Github link: 
---
Link to the dataset: https://archive.ics.uci.edu/ml/datasets/student+performance
student-por.csv (Portuguese language course) 


```{r}
library(readr)
library(tidyverse)
# install.packages('caTools')
library(caTools)
# install.packages("Metrics")
library(Metrics)
library(performance)
```


```{r}
#Por dataset
por<- read.table("student-por.csv", header =TRUE, sep = ";",stringsAsFactors = T)
summary(por)
str(por)
```


```{r}
### Subsetting numeric attributes.
numeric<- sapply(por, is.numeric) 
por.num<-por[,numeric]
str(por.num)

##### Normalize the dataset
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }

por.norm<- as.data.frame(lapply(por.num[,-c(14,15,16)], normalize))
por.norm<-cbind(por.norm,por.num[,14:16])
summary(por.norm)

```

```{r fig.height=30, fig.width=30, message=TRUE, paged.print=TRUE}

library(corrplot)
cor.por.num<-cor(por.num, method = "pearson")
corrplot.mixed(cor.por.num,upper ="number",lower="color")

### When applying Pearson correlation for numeric attributes. Pearson correlation coefficient was 0.82 for first period grade G1 and final grade G3 and 0.92 for second period grade G2 and the final grade G3.which indicate that G1 and G2 have strong positive correlation with G1.
```
```{r}
#### Since G1 and G2 are highly correlated with G3 as we see in the corrplot, we are not using G1 and G2 in predicting G3. 
### predicting G3
por.num3<-por.num[,-c(14,15)]
str(por.num3)
### predicting G1
por.num1<-por.num[,-c(16,15)]
str(por.num1)

############
#### Normalized data to predict G3
por.norm3<-por.norm[,-c(14,15)]
str(por.norm3)
#### Normalized data to predict G1
por.norm1<-por.norm[,-c(16,15)]
str(por.norm1)
```


```{r}
###linear regression model with numeric attribute 
###split the data into training and testing 
set.seed(11)
sample.por <- sample(1:nrow(por.norm), (nrow(por.norm)*.8))
#Pass the values contained in the sample to training
por.train <- por.norm[sample.por,]
#Pass the remaining of the data to testing
por.test <-por.norm[-sample.por,]

por.train3<-por.train[,-c(14,15)]
por.train1<-por.train[,-c(15,16)]

por.test3<-por.test[,-c(14,15)]
por.test1<-por.test[,-c(16,15)]
```

```{r}

###Apply Forward Selection and Backward Elimination to find the important attributes.
#### Multiple linear Regression models to predict G3
Full3<-lm(G3~.,por.num3)
Null3<-lm(G3~1,por.num3)
stepF3<- stepAIC(Null3, scope=list(lower=Null3, upper=Full3),direction= "forward", trace=F) ##library(MASS)
stepB3 <- stepAIC(Full3, direction= "backward", trace=F)                                    

# summary(Full3)
# summary(stepF3)
# summary(stepB3)
# compare_performance(Full3,stepF3,stepB3) # library(performance)

#### Multiple linear Regression model using normalized data to predict G1
nFull3<-lm(G3~.,por.norm3)
nNull3<-lm(G3~1,por.norm3)
nStepF3 <- stepAIC(nNull3, scope=list(lower=nNull3, upper=nFull3),direction= "forward", trace=F)
nStepB3 <- stepAIC(nFull3, direction= "backward", trace=F)

# summary(nFull3)
# summary(nStepF3)
# summary(nStepB3)
# compare_performance(nFull3,nStepF3,nStepB3) # library(performance)

compare_performance(Full3,stepF3,stepB3,nFull3,nStepF3,nStepB3)

### The Forward Selection and Backward Elimination give the same model(lm(formula = G1 ~ Medu + failures + freetime + goout, data = por.num)) with AIC=3194 compared to 3201 for the full model since the lower value of AIC is better model, the same values were for normalized data.
```
```{r}
#Create a model using the lm function (Multiple Linear Regression Model) using train dataset to predict G3.
train.F3 <- lm(G3~.,por.train3)
predict.F3<-round(predict(train.F3, por.test3 ,interval="prediction"),0)
# rmse(por.test3$G3, predict.F3)    ###install.packages("Metrics") ,library(Metrics)
errors.F3 <- predict.F3[,"fit"] - por.test3$G3
hist(errors.F3)
rmse.F3 <- sqrt(sum((errors.F3)^2)/nrow(por.test3))
rmse.F3 ### 2.91

#############################
train.SF3<-lm(formula = G3 ~ failures + Medu + goout + studytime + freetime, 
    data = por.train3)
predict.SF3 <-round(predict(train.SF3, por.test3,interval="prediction"),0)
# rmse(por.test3$G3, predict.SF3)
errors.SF3 <- predict.SF3[,"fit"] - por.test3$G3
hist(errors.SF3)
rmse.SF3 <- sqrt(sum((errors.SF3)^2)/nrow(por.test3))
rmse.SF3 ###   2.86

compare_performance(train.F3,train.SF3)  ###library(performance)
## the performance of the partial model with 5 features only (failures + Medu + goout + studytime + freetime) is almost the same as the full model
```

```{r}

# Apply Forward Selection and Backward Elimination to find the important attributes.
#### Multiple linear Regression models to predict G1
Full1<-lm(G1~.,por.num1)
Null1<-lm(G1~1,por.num1)
StepF1<- stepAIC(Null1, scope=list(lower=Null1, upper=Full1),direction= "forward", trace=F) ##library(MASS)
StepB1 <- stepAIC(Full1, direction= "backward", trace=F)                                    ##library(MASS)

# summary(Full1)
# summary(StepF1)
# summary(StepB1)
# compare_performance(Full1,StepF1 ,StepB1) # library(performance)

#### Multiple linear Regression model using normalized data to predict G1
nFull1<-lm(G1~.,por.norm1)
nNull1<-lm(G1~1,por.norm1)
nStepF1 <- stepAIC(nNull1, scope=list(lower=nNull1, upper=nFull1),direction= "forward", trace=F)
nStepB1 <- stepAIC(nFull1, direction= "backward", trace=F)

# summary(nFull1)
# summary(nStepF1)
# summary(nStepB1)
# compare_performance(nFull1,nStepF1,nStepB1) # library(performance)
compare_performance(Full1,StepF1 ,StepB1,nFull1,nStepF1,nStepB1)

### The Forward Selection and Backward Elimination give the same model(lm(formula = G1 ~ Medu + failures + freetime + goout, data = por.num)) with AIC=2982 compared to 2991 for the full model since the lower value of AIC is better model, the same values were for normalized data.
```

```{r}
#Create a model using the lm function (Multiple Linear Regression Model) using full attributes.
train.F1<-lm(G1~.,por.train1)
predict.F1<-round(predict(train.F1, por.test1 ,interval="prediction"),0)
errors.F1 <- predict.F1[,"fit"] - por.test1$G1
hist(errors.F1)
rmse.F1 <- sqrt(sum((errors.F1)^2)/nrow(por.test1))
rmse.F1 ### 2.46
# rmse(por.test1$G1, predict.F1)    ###install.packages("Metrics") ,library(Metrics)

###############################
#Create a model using the lm function (Multiple Linear Regression Model) using 5 attributes.
train.SF1 <-lm(formula = G1 ~ failures + Medu + goout + studytime + freetime, 
    data = por.train1)
predict.SF1 <-round(predict(train.SF1, por.test1,interval="prediction"),0)
errors.SF1 <- predict.SF1[,"fit"] - por.test1$G1
hist(errors.SF1)
rmse.SF1 <- sqrt(sum((errors.SF1)^2)/nrow(por.test1))
rmse.SF1 ###  2.46
# rmse(por.test1$G1, predict.por.SF1)

compare_performance(train.F1,train.SF1)  ###library(performance)
## the performance of the partial model with 5 features only (failures + Medu + goout + studytime + freetime) is almost the same as the full model

```
