

---
title: "Student Performance prediction-Multiple Linear Regression- Math Dataset"
Github link: 
---
Link to the dataset: https://archive.ics.uci.edu/ml/datasets/student+performance

student-mat.csv (Math course) 

```{r}
library(readr)
library(tidyverse)
# install.packages('caTools')
library(caTools)
# install.packages("Metrics")
library(Metrics)
library(performance)
```


```{r}
#Math dataset
mat<- read.table("student-mat.csv", header =TRUE, sep = ";",stringsAsFactors = T)
summary(mat)
str(mat)
```


```{r}
### Subsetting numeric attributes.
numeric<- sapply(mat, is.numeric) 
mat.num<-mat[,numeric]
str(mat.num)

##### Normalize the dataset
normalize <- function(x) {
return ((x - min(x)) / (max(x) - min(x))) }

mat.norm<- as.data.frame(lapply(mat.num[,-c(14,15,16)], normalize))
mat.norm<-cbind(mat.norm,mat.num[,14:16])
summary(mat.norm)

```

```{r fig.height=30, fig.width=30, message=TRUE, paged.print=TRUE}

library(corrplot)
cor.mat.num<-cor(mat.num, method = "pearson")
corrplot.mixed(cor.mat.num,upper ="number",lower="color")

### When applying Pearson correlation for numeric attributes. Pearson correlation coefficient was 0.80 for first period grade G1 and final grade G1 and 0.9 for second period grade G2 and the final grade G1.which indicate that G1 and G2 have strong positive correlation with G1.
```
```{r}
#### Since G1, G2 and G3 are highly correlated as we see in the corrplot, we are not using G1 and G2 in predicting G3. 
### predicting G3
mat.num3<-mat.num[,-c(14,15)]
str(mat.num3)
### predicting G1
mat.num1<-mat.num[,-c(16,15)]
str(mat.num1)

############
#### Normalized data to predict G3
mat.norm3<-mat.norm[,-c(14,15)]
str(mat.norm3)
#### Normalized data to predict G1
mat.norm1<-mat.norm[,-c(16,15)]
str(mat.norm1)
```


```{r}
###linear regression model with numeric attribute 
###split the data into training and testing 
set.seed(11)
sample.mat <- sample(1:nrow(mat.norm), (nrow(mat.norm)*.8))
#Pass the values contained in the sample to training
mat.train <- mat.norm[sample.mat,]
#Pass the remaining of the data to testing
mat.test <-mat.norm[-sample.mat,]

mat.train3<-mat.train[,-c(14,15)]
mat.train1<-mat.train[,-c(15,16)]

mat.test3<-mat.test[,-c(14,15)]
mat.test1<-mat.test[,-c(16,15)]
```

```{r}

###Apply Forward Selection and Backward Elimination to find the important attributes.
#### Multiple linear Regression models to predict G3
Full3<-lm(G3~.,mat.num3)
Null3<-lm(G3~1,mat.num3)
stepF3<- stepAIC(Null3, scope=list(lower=Null3, upper=Full3),direction= "forward", trace=F) ##library(MASS)
stepB3 <- stepAIC(Full3, direction= "backward", trace=F)                                    

# summary(Full3)
# summary(stepF3)
# summary(stepB3)
# compare_performance(Full3,stepF3,stepB3) # library(performance)

#### Multiple linear Regression model using normalized data to predict G1
nFull3<-lm(G3~.,mat.norm3)
nNull3<-lm(G3~1,mat.norm3)
nStepF3 <- stepAIC(nNull3, scope=list(lower=nNull3, upper=nFull3),direction= "forward", trace=F)
nStepB3 <- stepAIC(nFull3, direction= "backward", trace=F)

# summary(nFull3)
# summary(nStepF3)
# summary(nStepB3)
# compare_performance(nFull3,nStepF3,nStepB3) # library(performance)

compare_performance(Full3,stepF3,stepB3,nFull3,nStepF3,nStepB3)

### The Forward Selection and Backward Elimination give the same model(lm(formula = G1 ~ Medu + failures + freetime + goout, data = mat.num)) with AIC=2264 compared to 2273 for the full model since the lower value of AIC is better model, the same values were for normalized data.
```
```{r}
#Create a model using the lm function (Multiple Linear Regression Model) using train dataset to predict G3.
train.F3 <- lm(G3~.,mat.train3)
predict.F3<-round(predict(train.F3, mat.test3 ),0)
# rmse(mat.test3$G3, predict.F3)    ###install.packages("Metrics") ,library(Metrics)
errors.F3 <- predict.F3 - mat.test3$G3
hist(errors.F3)
rmse.F3 <- sqrt(sum((errors.F3)^2)/nrow(mat.test3))
rmse.F3 ### 4.39

#############################
train.SF3<-lm(formula = G3 ~ failures + Medu + goout + studytime + freetime, 
    data = mat.train3)
predict.SF3 <-round(predict(train.SF3, mat.test3,interval="prediction"),0)
# rmse(mat.test3$G3, predict.SF3)
errors.SF3 <- predict.SF3[,"fit"] - mat.test3$G3
hist(errors.SF3)
rmse.SF3 <- sqrt(sum((errors.SF3)^2)/nrow(mat.test3))
rmse.SF3 ###  4.45

compare_performance(train.F3,train.SF3)  ###library(performance)
## the performance of the partial model with 5 features only (failures + Medu + goout + studytime + freetime) is almost the same as the full model
```


```{r}

# Apply Forward Selection and Backward Elimination to find the important attributes.
#### Multiple linear Regression models to predict G1
Full1<-lm(G1~.,mat.num1)
Null1<-lm(G1~1,mat.num1)
StepF1<- stepAIC(Null1, scope=list(lower=Null1, upper=Full1),direction= "forward", trace=F) ##library(MASS)
StepB1 <- stepAIC(Full1, direction= "backward", trace=F)                                    ##library(MASS)

# summary(Full1)
# summary(StepF1)
# summary(StepB1)
# compare_performance(Full1,StepF1 ,StepB1) # library(performance)

#### Multiple linear Regression model using normalized data to predict G1
nFull1<-lm(G1~.,mat.norm1)
nNull1<-lm(G1~1,mat.norm1)
nStepF1 <- stepAIC(nNull1, scope=list(lower=nNull1, upper=nFull1),direction= "forward", trace=F)
nStepB1 <- stepAIC(nFull1, direction= "backward", trace=F)

# summary(nFull1)
# summary(nStepF1)
# summary(nStepB1)
# compare_performance(nFull1,nStepF1,nStepB1) # library(performance)
compare_performance(Full1,StepF1 ,StepB1,nFull1,nStepF1,nStepB1)

### The Forward Selection and Backward Elimination give the same model(lm(formula = G1 ~ Medu + failures + freetime + goout, data = mat.num)) with AIC=2008 compared to 2019 for the full model since the lower value of AIC is better model, the same values were for normalized data.
```

```{r}
#Create a model using the lm function (Multiple Linear Regression Model) using full attributes.
train.F1<-lm(G1~.,mat.train1)
predict.F1<-round(predict(train.F1, mat.test1 ,interval="prediction"),0)
errors.F1 <- predict.F1[,"fit"] - mat.test1$G1
hist(errors.F1)
rmse.F1 <- sqrt(sum((errors.F1)^2)/nrow(mat.test1))
rmse.F1 ### 2.8
# rmse(mat.test1$G1, predict.F1)    ###install.packages("Metrics") ,library(Metrics)

###############################
#Create a model using the lm function (Multiple Linear Regression Model) using 5 attributes.
train.SF1 <-lm(formula = G1 ~ failures + Medu + goout + studytime + freetime, 
    data = mat.train1)
predict.SF1 <-round(predict(train.SF1, mat.test1,interval="prediction"),0)
errors.SF1 <- predict.SF1[,"fit"] - mat.test1$G1
hist(errors.mat.SF1)
rmse.SF1 <- sqrt(sum((errors.SF1)^2)/nrow(mat.test1))
rmse.SF1 ### 2.9
# rmse(mat.test1$G1, predict.mat.SF1)

compare_performance(train.F1,train.SF1)  ###library(performance)
## the performance of the partial model with 5 features only (failures + Medu + goout + studytime + freetime) is almost the same as the full model

```
